{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05fabbdb-18af-4a9e-80e0-0c20e03fbe71",
   "metadata": {},
   "source": [
    "# A Second Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c95112a-00ff-48f4-a28f-257e177078cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pbs/throng/training/universite-hiver/rag-envs/rag2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5492217d-b1ef-4ccc-9a87-c4a33bc85cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "model_general = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "tokenizer_sci = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "model_sci = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e07fa821-fba4-4035-b3d0-ceb2ff9d4ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/arxiv_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d7666c9-724e-4381-aaac-9f934cdb0d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51774"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd7ce5eb-2c3d-46ac-a900-553770790e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>summaries</th>\n",
       "      <th>terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
       "      <td>Stereo matching is one of the widely used tech...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>The recent advancements in artificial intellig...</td>\n",
       "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
       "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
       "      <td>['cs.CV', 'cs.AI']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
       "      <td>Consistency training has proven to be an advan...</td>\n",
       "      <td>['cs.CV']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Background-Foreground Segmentation for Interio...</td>\n",
       "      <td>To ensure safety in automated driving, the cor...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titles                                          summaries                        terms\n",
       "0  Survey on Semantic Stereo Matching / Semantic ...  Stereo matching is one of the widely used tech...           ['cs.CV', 'cs.LG']\n",
       "1  FUTURE-AI: Guiding Principles and Consensus Re...  The recent advancements in artificial intellig...  ['cs.CV', 'cs.AI', 'cs.LG']\n",
       "2  Enforcing Mutual Consistency of Hard Regions f...  In this paper, we proposed a novel mutual cons...           ['cs.CV', 'cs.AI']\n",
       "3  Parameter Decoupling Strategy for Semi-supervi...  Consistency training has proven to be an advan...                    ['cs.CV']\n",
       "4  Background-Foreground Segmentation for Interio...  To ensure safety in automated driving, the cor...           ['cs.CV', 'cs.LG']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d41a2bb-c647-4339-ab45-6cf0d9639304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "terms\n",
       "cs.CV      30413\n",
       "cs.LG      29067\n",
       "stat.ML    15578\n",
       "cs.AI       7944\n",
       "eess.IV     2484\n",
       "cs.RO       1896\n",
       "cs.CL       1620\n",
       "cs.NE       1296\n",
       "cs.CR        717\n",
       "cs.SI        678\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.terms.apply(eval).explode().value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a68dc55-d807-4da2-9a13-4190e7c37592",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data[data['terms'].str.contains('cs.CL')][['titles', 'summaries']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72a36157-8d43-417e-9b92-cef4fdcd22df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1620"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b73a729-8883-4e39-8f6e-3753ee68f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_with_scibert(texts, batch_size=16):\n",
    "    embeddings = []\n",
    "    model_sci.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(texts), batch_size)):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            encoded = tokenizer_sci(batch, padding=True, truncation=True, return_tensors='pt')\n",
    "            output = model_sci(**encoded)\n",
    "            mean_pooling = output.last_hidden_state.mean(dim=1)\n",
    "            embeddings.append(mean_pooling)\n",
    "    return torch.cat(embeddings).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98be4752-a4ec-485f-a9fe-2cb334893dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/102 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|██████████| 102/102 [00:50<00:00,  2.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# Embed abstracts\n",
    "summaries = data2['summaries'].tolist()\n",
    "embeddings_general = model_general.encode(summaries, convert_to_numpy=True)\n",
    "embeddings_sci = embed_with_scibert(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c147e013-8078-43a1-ad32-2d8881e68ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_keyword_matches(text, query):\n",
    "    query_words = set(re.findall(r'\\w+', query.lower()))\n",
    "    text_words = set(re.findall(r'\\w+', text.lower()))\n",
    "    return len(query_words.intersection(text_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "be04fc06-25f2-4e4a-b95e-bed8115ad144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_chunks(data, query, mode=\"keywords\", top_k=5):\n",
    "    query_emb_sci = embed_with_scibert([query])[0].reshape(1, -1)\n",
    "    query_emb_general = model_general.encode([query])[0].reshape(1, -1)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        summary = data.loc[i, 'summaries']\n",
    "        title = data.loc[i, 'titles']\n",
    "        keyword_hits = count_keyword_matches(summary, query)\n",
    "\n",
    "        sim_sci = cosine_similarity(query_emb_sci, embeddings_sci[i].reshape(1, -1))[0][0]\n",
    "        sim_gen = cosine_similarity(query_emb_general, embeddings_general[i].reshape(1, -1))[0][0]\n",
    "\n",
    "        results.append({\n",
    "            \"title\": title,\n",
    "            \"summary\": summary,\n",
    "            \"keyword_matches\": keyword_hits,\n",
    "            \"sim_sciBERT\": sim_sci,\n",
    "            \"sim_miniLM\": sim_gen\n",
    "        })\n",
    "\n",
    "    if mode == \"keywords\":\n",
    "        ranked = sorted(results, key=lambda x: x['keyword_matches'], reverse=True)\n",
    "    elif mode == \"scibert\":\n",
    "        ranked = sorted(results, key=lambda x: x['sim_sciBERT'], reverse=True)\n",
    "    elif mode == \"minilm\":\n",
    "        ranked = sorted(results, key=lambda x: x['sim_miniLM'], reverse=True)\n",
    "    else:\n",
    "        raise ValueError(\"Mode must be one of: 'keywords', 'scibert', 'minilm'\")\n",
    "\n",
    "    return ranked[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c67c0023-efd5-4059-b2d5-8137f73f7182",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Approaches combining knowledge graphs and text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6fd10b8e-f12c-4fab-91c9-1cff5fee0f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = client.chat(model, messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': f\"\"\"Approaches combining knowledge graphs and text\"\"\"\n",
    "        },\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6c708f19-844a-4926-8d64-0678b546edac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Combining Knowledge Graphs (KGs) and Text: A Quick‑Start Guide\n",
      "\n",
      "| # | Category | Typical Methods | Core Idea | Representative Papers |\n",
      "|---|----------|-----------------|-----------|-----------------------|\n",
      "| 1 | **KG Embedding + Textual Context** | Joint learning of KG triples and document sentences | Encode entities/relations **and** sentences into a shared vector space | *KG-BERT* (2019), *K-BERT* (2020), *ERNIE* (2020) |\n",
      "| 2 | **Graph Neural Networks (GNNs) + Text** | Use a GNN to propagate information across entities while a Transformer processes text | Combine local graph structure with global language context | *Text2KG* (2019), *KEPLER* (2020) |\n",
      "| 3 | **Knowledge‑Enhanced Language Models** | Augment pre‑training or fine‑tuning with KG facts | Use KG to guide attention or add a knowledge head | *K-Adapter* (2021), *K-BERT* (2020), *K-GPT* (2021) |\n",
      "| 4 | **KG‑Guided Retrieval + Text Generation** | Retrieve relevant KG sub‑graphs before generating or classifying | Provide a “memory” of factual knowledge | *K-BERT‑Retriever* (2021), *K2N* (2022) |\n",
      "| 5 | **Text‑to‑KG Construction** | Parse text into KG triples (information extraction) | Build or expand a KG from unstructured data | *Text2KG* (2019), *OpenIE‑KG* (2020) |\n",
      "| 6 | **Cross‑Modal Retrieval / QA** | Use KG to answer text‑based queries | Bridge the gap between natural language questions and KG reasoning | *K-BERT + QA* (2020), *KIQA* (2021) |\n",
      "\n",
      "---\n",
      "\n",
      "## 1. KG Embedding + Textual Context\n",
      "\n",
      "**Goal:** Learn embeddings that respect both symbolic graph structure and the semantics of surrounding text.\n",
      "\n",
      "### Typical Pipeline\n",
      "1. **KG Side** – Train a traditional embedding model (TransE, ComplEx, RotatE, etc.) on triples `(h, r, t)`.\n",
      "2. **Text Side** – Encode sentences or documents that mention entities using a language model (BERT, RoBERTa, GPT‑2, etc.).\n",
      "3. **Joint Objective** – Either:\n",
      "   * **Contrastive**: Align entity embeddings with sentence embeddings containing that entity.\n",
      "   * **Multimodal**: Predict triples from text or reconstruct text from triples.\n",
      "\n",
      "### Key Ideas\n",
      "- **Entity Linking**: Map mentions in text to KG entities.  \n",
      "- **Contextualized Embeddings**: Use *contextual* embeddings for entities (e.g., use BERT’s token embeddings for the entity name).  \n",
      "- **Dual‑Encoder**: One encoder for KG, another for text; train with a joint loss.\n",
      "\n",
      "### Representative Work\n",
      "| Paper | Year | Highlights |\n",
      "|-------|------|------------|\n",
      "| **K-BERT** | 2020 | Inserts entity IDs into BERT tokens, enabling the model to attend to KG knowledge during pre‑training. |\n",
      "| **KG-BERT** | 2019 | Uses knowledge graph to augment BERT with an entity graph attention layer. |\n",
      "| **ERNIE** | 2020 | Introduces “knowledge masking” to force BERT to learn relations. |\n",
      "| **K-GNN** | 2020 | Combines GCN with Transformer for entity classification. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Graph Neural Networks (GNNs) + Text\n",
      "\n",
      "**Goal:** Explicitly propagate graph signals while simultaneously leveraging language signals.\n",
      "\n",
      "### Typical Architecture\n",
      "```\n",
      "Text Encoder (Transformer)  →  Entity Representation\n",
      "            |                         |\n",
      "            +----- GCN on KG -----+\n",
      "            |                         |\n",
      "        Final Entity Embedding  →  Downstream Task\n",
      "```\n",
      "\n",
      "### Common Techniques\n",
      "- **Entity‑Centric Aggregation**: For each entity, aggregate neighboring entity embeddings and combine with text embedding.\n",
      "- **Attention over Relations**: Weight message passing by relation type (e.g., `attn(r)`).\n",
      "- **Node Classification / Link Prediction**: Use the fused representation for entity classification or predicting missing edges.\n",
      "\n",
      "### Notable Models\n",
      "| Model | Year | Key Contributions |\n",
      "|-------|------|-------------------|\n",
      "| **KEPLER** | 2020 | Uses a Knowledge‑Enhanced Language Encoder with GCNs for entity typing. |\n",
      "| **Text2KG** | 2019 | Jointly trains a BERT encoder and a GCN for knowledge graph completion. |\n",
      "| **KGCN** | 2021 | Applies a heterogeneous GCN to encode multi‑relational KG signals into text. |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Knowledge‑Enhanced Language Models\n",
      "\n",
      "**Goal:** Equip a powerful language model (LM) with explicit access to KG facts.\n",
      "\n",
      "### Common Approaches\n",
      "\n",
      "| Approach | How it Works |\n",
      "|----------|--------------|\n",
      "| **Knowledge Retrieval** | Query KG at inference time; feed retrieved facts as additional tokens or context. |\n",
      "| **Knowledge Attention** | Add a separate attention head that attends over KG embeddings. |\n",
      "| **Knowledge Masking** | During pre‑training, mask entity tokens and require the LM to predict them using KG knowledge. |\n",
      "| **Adapter Modules** | Insert lightweight adapter layers that are trained on KG data while freezing the LM. |\n",
      "\n",
      "### Representative Models\n",
      "| Model | Year | Unique Angle |\n",
      "|-------|------|--------------|\n",
      "| **K-Adapter** | 2021 | Adapter layers trained on KG triples, integrated into a frozen BERT. |\n",
      "| **K-BERT** | 2020 | Knowledge‑augmented BERT with entity ID tokens and graph attention. |\n",
      "| **K-GPT** | 2021 | GPT‑2 conditioned on KG via knowledge‑conditioned token generation. |\n",
      "| **ERNIE 3.0** | 2022 | Multi‑granularity knowledge integration (entity, relation, concept). |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. KG‑Guided Retrieval + Text Generation\n",
      "\n",
      "**Goal:** Use a KG as a “memory” for generating or classifying text, especially for tasks that need factual grounding.\n",
      "\n",
      "### Retrieval–Generation Loop\n",
      "\n",
      "1. **Query**: From the input text, derive a query (e.g., entity names, relation patterns).\n",
      "2. **Retrieve**: Fetch a sub‑graph (entities + relations) from the KG relevant to the query.\n",
      "3. **Encode**: Jointly encode retrieved KG and input text.\n",
      "4. **Generate**: Use a decoder (Transformer, GPT‑2, etc.) to produce the answer or text.\n",
      "\n",
      "### Applications\n",
      "- **Question‑Answering**: Retrieve answer sub‑graph → generate natural language answer.\n",
      "- **Fact‑Checking**: Retrieve supporting facts → generate verdict.\n",
      "- **Chatbots**: Retrieve user‑specific knowledge → generate context‑aware replies.\n",
      "\n",
      "### Key Papers\n",
      "| Paper | Year | Notes |\n",
      "|-------|------|-------|\n",
      "| **K-BERT‑Retriever** | 2021 | Integrates BM25‑style retrieval with BERT. |\n",
      "| **K2N** | 2022 | Uses knowledge graphs for neural open‑domain QA. |\n",
      "| **KALM** | 2023 | Knowledge‑augmented Language Model with dynamic retrieval. |\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Text‑to‑KG Construction (Information Extraction)\n",
      "\n",
      "**Goal:** Populate or expand a KG from raw text.\n",
      "\n",
      "### Typical Steps\n",
      "1. **Named Entity Recognition (NER)** → Detect entities.\n",
      "2. **Relation Extraction** → Identify triples `(h, r, t)` via supervised or unsupervised methods.\n",
      "3. **Coreference & Entity Linking** → Resolve mentions to KG IDs.\n",
      "4. **KG Update** → Insert new triples, possibly with confidence scores.\n",
      "\n",
      "### State‑of‑the‑Art Systems\n",
      "- **Text2KG** (2019) – Jointly learns NER and relation extraction using a shared encoder.\n",
      "- **OpenIE‑KG** (2020) – Uses Open Information Extraction with a knowledge base mapping step.\n",
      "- **TACRED** + **HKG** – Benchmark datasets for training relation extraction models.\n",
      "\n",
      "---\n",
      "\n",
      "## 6. Cross‑Modal Retrieval / QA\n",
      "\n",
      "**Goal:** Bridge natural language queries and KG reasoning.\n",
      "\n",
      "### Common Architectures\n",
      "- **Dual‑Encoder**: One encoder for the query (BERT) and another for the KG (GCN). Use cosine similarity to retrieve top‑k triples.\n",
      "- **Joint‑Encoder**: Concatenate query and KG sub‑graph into one input sequence; fine‑tune on QA or classification.\n",
      "- **Reasoning Layer**: Apply multi‑hop reasoning on the KG (e.g., GNN or rule‑based) before matching with the query.\n",
      "\n",
      "### Notable Systems\n",
      "| System | Year | Use‑case |\n",
      "|--------|------|----------|\n",
      "| **K-BERT‑QA** | 2020 | Question answering with KG‑augmented BERT. |\n",
      "| **KIQA** | 2021 | Knowledge‑informed question answering benchmark. |\n",
      "| **TREC KBQA** | 2017 | Early benchmark for KG QA. |\n",
      "\n",
      "---\n",
      "\n",
      "## Practical Tips & Pitfalls\n",
      "\n",
      "| Tip | Why it matters |\n",
      "|-----|----------------|\n",
      "| **Entity Linking First** | Poor linking leads to noisy joint representations. |\n",
      "| **Scale the KG** | Large KGs can explode memory; use sampling or sub‑graph extraction. |\n",
      "| **Fine‑tune on Downstream Task** | Pre‑trained KG embeddings may need task‑specific adaptation. |\n",
      "| **Handle OOV Entities** | Use sub‑word embeddings or placeholder tokens. |\n",
      "| **Balance Text vs KG Loss** | Weighted loss terms prevent one modality from dominating. |\n",
      "| **Use Pre‑trained LMs** | Leverage BERT, RoBERTa, GPT‑2, etc., as strong backbones. |\n",
      "\n",
      "---\n",
      "\n",
      "## Quick Starter Code Snippets\n",
      "\n",
      "### 1. Joint Encoder (PyTorch)\n",
      "\n",
      "```python\n",
      "import torch, torch.nn as nn\n",
      "from transformers import BertModel, BertTokenizer\n",
      "from torch_geometric.nn import GCNConv\n",
      "\n",
      "class KGTextModel(nn.Module):\n",
      "    def __init__(self, kg_dim=256, txt_dim=768, num_rel=100):\n",
      "        super().__init__()\n",
      "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
      "        self.gcn1 = GCNConv(kg_dim, kg_dim)\n",
      "        self.gcn2 = GCNConv(kg_dim, kg_dim)\n",
      "        self.rel_emb = nn.Embedding(num_rel, kg_dim)\n",
      "        self.fc = nn.Linear(txt_dim + kg_dim, 2)  # e.g., classification\n",
      "\n",
      "    def forward(self, txt_input_ids, txt_attention_mask,\n",
      "                kg_x, kg_edge_index, kg_edge_type):\n",
      "        # Text encoder\n",
      "        txt_out = self.bert(txt_input_ids, attention_mask=txt_attention_mask)[0]\n",
      "        txt_rep = txt_out[:,0,:]  # CLS token\n",
      "\n",
      "        # KG encoder\n",
      "        kg_x = kg_x + self.rel_emb(kg_edge_type)\n",
      "        kg_x = torch.relu(self.gcn1(kg_x, kg_edge_index))\n",
      "        kg_x = torch.relu(self.gcn2(kg_x, kg_edge_index))\n",
      "        kg_rep = torch.mean(kg_x, dim=0)  # simple readout\n",
      "\n",
      "        # Fuse\n",
      "        fused = torch.cat([txt_rep, kg_rep], dim=-1)\n",
      "        logits = self.fc(fused)\n",
      "        return logits\n",
      "```\n",
      "\n",
      "### 2. Knowledge Retrieval with BM25 + BERT (Pseudo‑Code)\n",
      "\n",
      "```python\n",
      "# Preprocess KG triples into \"textual facts\"\n",
      "facts = [f\"{h} {r} {t}\" for h, r, t in triples]\n",
      "\n",
      "# Build BM25 index\n",
      "from rank_bm25 import BM25Okapi\n",
      "tokenized_facts = [fact.split() for fact in facts]\n",
      "bm25 = BM25Okapi(tokenized_facts)\n",
      "\n",
      "def retrieve(query, k=5):\n",
      "    tokenized_query = query.split()\n",
      "    scores = bm25.get_scores(tokenized_query)\n",
      "    top_idx = scores.argsort()[-k:][::-1]\n",
      "    return [facts[i] for i in top_idx]\n",
      "\n",
      "# During inference\n",
      "retrieved = retrieve(user_query)\n",
      "# Encode retrieved facts with BERT + user query for final prediction\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## Bibliography (Select)\n",
      "\n",
      "- **K-BERT** – X. Liu et al., 2020. *ACL*  \n",
      "- **KG-BERT** – C. Wang et al., 2019. *EMNLP*  \n",
      "- **ERNIE** – Y. Zhang et al., 2020. *ACL*  \n",
      "- **KEPLER** – Z. Wang et al., 2020. *ACL*  \n",
      "- **Text2KG** – Y. Ji et al., 2019. *ACL*  \n",
      "- **K-Adapter** – M. Li et al., 2021. *ACL*  \n",
      "- **K-GPT** – S. Liu et al., 2021. *NAACL*  \n",
      "- **KIQA** – S. B. Yang et al., 2021. *AAAI*  \n",
      "- **TACRED** – A. Liu et al., 2018. *ACL*  \n",
      "\n",
      "---\n",
      "\n",
      "### TL;DR\n",
      "\n",
      "1. **Learn embeddings that sit in the same space**: Use joint objectives (contrastive, multimodal) to align KG entities with text tokens.  \n",
      "2. **Let graphs talk to language models**: GCN/GraphSAGE + Transformers or specialized knowledge heads.  \n",
      "3. **Retrieve or condition on KG facts**: Dynamic retrieval or static “knowledge tokens” during inference.  \n",
      "4. **Build or extend KGs from text**: Joint NER/RE pipelines, then link to existing KG.  \n",
      "5. **Fine‑tune for your downstream task**: Even the best joint model still benefits from task‑specific fine‑tuning.\n",
      "\n",
      "With these strategies, you can harness the structured knowledge of KGs and the expressive power of modern language models to build smarter NLP systems. Happy hacking!\n"
     ]
    }
   ],
   "source": [
    "print(answer.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7efe0a1-6f92-4962-8bd5-775e2d137ed7",
   "metadata": {},
   "source": [
    "## Combining Knowledge Graphs (KGs) and Text: A Quick‑Start Guide\n",
    "\n",
    "| # | Category | Typical Methods | Core Idea | Representative Papers |\n",
    "|---|----------|-----------------|-----------|-----------------------|\n",
    "| 1 | **KG Embedding + Textual Context** | Joint learning of KG triples and document sentences | Encode entities/relations **and** sentences into a shared vector space | *KG-BERT* (2019), *K-BERT* (2020), *ERNIE* (2020) |\n",
    "| 2 | **Graph Neural Networks (GNNs) + Text** | Use a GNN to propagate information across entities while a Transformer processes text | Combine local graph structure with global language context | *Text2KG* (2019), *KEPLER* (2020) |\n",
    "| 3 | **Knowledge‑Enhanced Language Models** | Augment pre‑training or fine‑tuning with KG facts | Use KG to guide attention or add a knowledge head | *K-Adapter* (2021), *K-BERT* (2020), *K-GPT* (2021) |\n",
    "| 4 | **KG‑Guided Retrieval + Text Generation** | Retrieve relevant KG sub‑graphs before generating or classifying | Provide a “memory” of factual knowledge | *K-BERT‑Retriever* (2021), *K2N* (2022) |\n",
    "| 5 | **Text‑to‑KG Construction** | Parse text into KG triples (information extraction) | Build or expand a KG from unstructured data | *Text2KG* (2019), *OpenIE‑KG* (2020) |\n",
    "| 6 | **Cross‑Modal Retrieval / QA** | Use KG to answer text‑based queries | Bridge the gap between natural language questions and KG reasoning | *K-BERT + QA* (2020), *KIQA* (2021) |\n",
    "\n",
    "---\n",
    "\n",
    "## 1. KG Embedding + Textual Context\n",
    "\n",
    "**Goal:** Learn embeddings that respect both symbolic graph structure and the semantics of surrounding text.\n",
    "\n",
    "### Typical Pipeline\n",
    "1. **KG Side** – Train a traditional embedding model (TransE, ComplEx, RotatE, etc.) on triples `(h, r, t)`.\n",
    "2. **Text Side** – Encode sentences or documents that mention entities using a language model (BERT, RoBERTa, GPT‑2, etc.).\n",
    "3. **Joint Objective** – Either:\n",
    "   * **Contrastive**: Align entity embeddings with sentence embeddings containing that entity.\n",
    "   * **Multimodal**: Predict triples from text or reconstruct text from triples.\n",
    "\n",
    "### Key Ideas\n",
    "- **Entity Linking**: Map mentions in text to KG entities.  \n",
    "- **Contextualized Embeddings**: Use *contextual* embeddings for entities (e.g., use BERT’s token embeddings for the entity name).  \n",
    "- **Dual‑Encoder**: One encoder for KG, another for text; train with a joint loss.\n",
    "\n",
    "### Representative Work\n",
    "| Paper | Year | Highlights |\n",
    "|-------|------|------------|\n",
    "| **K-BERT** | 2020 | Inserts entity IDs into BERT tokens, enabling the model to attend to KG knowledge during pre‑training. |\n",
    "| **KG-BERT** | 2019 | Uses knowledge graph to augment BERT with an entity graph attention layer. |\n",
    "| **ERNIE** | 2020 | Introduces “knowledge masking” to force BERT to learn relations. |\n",
    "| **K-GNN** | 2020 | Combines GCN with Transformer for entity classification. |\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Graph Neural Networks (GNNs) + Text\n",
    "\n",
    "**Goal:** Explicitly propagate graph signals while simultaneously leveraging language signals.\n",
    "\n",
    "### Typical Architecture\n",
    "```\n",
    "Text Encoder (Transformer)  →  Entity Representation\n",
    "            |                         |\n",
    "            +----- GCN on KG -----+\n",
    "            |                         |\n",
    "        Final Entity Embedding  →  Downstream Task\n",
    "```\n",
    "\n",
    "### Common Techniques\n",
    "- **Entity‑Centric Aggregation**: For each entity, aggregate neighboring entity embeddings and combine with text embedding.\n",
    "- **Attention over Relations**: Weight message passing by relation type (e.g., `attn(r)`).\n",
    "- **Node Classification / Link Prediction**: Use the fused representation for entity classification or predicting missing edges.\n",
    "\n",
    "### Notable Models\n",
    "| Model | Year | Key Contributions |\n",
    "|-------|------|-------------------|\n",
    "| **KEPLER** | 2020 | Uses a Knowledge‑Enhanced Language Encoder with GCNs for entity typing. |\n",
    "| **Text2KG** | 2019 | Jointly trains a BERT encoder and a GCN for knowledge graph completion. |\n",
    "| **KGCN** | 2021 | Applies a heterogeneous GCN to encode multi‑relational KG signals into text. |\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Knowledge‑Enhanced Language Models\n",
    "\n",
    "**Goal:** Equip a powerful language model (LM) with explicit access to KG facts.\n",
    "\n",
    "### Common Approaches\n",
    "\n",
    "| Approach | How it Works |\n",
    "|----------|--------------|\n",
    "| **Knowledge Retrieval** | Query KG at inference time; feed retrieved facts as additional tokens or context. |\n",
    "| **Knowledge Attention** | Add a separate attention head that attends over KG embeddings. |\n",
    "| **Knowledge Masking** | During pre‑training, mask entity tokens and require the LM to predict them using KG knowledge. |\n",
    "| **Adapter Modules** | Insert lightweight adapter layers that are trained on KG data while freezing the LM. |\n",
    "\n",
    "### Representative Models\n",
    "| Model | Year | Unique Angle |\n",
    "|-------|------|--------------|\n",
    "| **K-Adapter** | 2021 | Adapter layers trained on KG triples, integrated into a frozen BERT. |\n",
    "| **K-BERT** | 2020 | Knowledge‑augmented BERT with entity ID tokens and graph attention. |\n",
    "| **K-GPT** | 2021 | GPT‑2 conditioned on KG via knowledge‑conditioned token generation. |\n",
    "| **ERNIE 3.0** | 2022 | Multi‑granularity knowledge integration (entity, relation, concept). |\n",
    "\n",
    "---\n",
    "\n",
    "## 4. KG‑Guided Retrieval + Text Generation\n",
    "\n",
    "**Goal:** Use a KG as a “memory” for generating or classifying text, especially for tasks that need factual grounding.\n",
    "\n",
    "### Retrieval–Generation Loop\n",
    "\n",
    "1. **Query**: From the input text, derive a query (e.g., entity names, relation patterns).\n",
    "2. **Retrieve**: Fetch a sub‑graph (entities + relations) from the KG relevant to the query.\n",
    "3. **Encode**: Jointly encode retrieved KG and input text.\n",
    "4. **Generate**: Use a decoder (Transformer, GPT‑2, etc.) to produce the answer or text.\n",
    "\n",
    "### Applications\n",
    "- **Question‑Answering**: Retrieve answer sub‑graph → generate natural language answer.\n",
    "- **Fact‑Checking**: Retrieve supporting facts → generate verdict.\n",
    "- **Chatbots**: Retrieve user‑specific knowledge → generate context‑aware replies.\n",
    "\n",
    "### Key Papers\n",
    "| Paper | Year | Notes |\n",
    "|-------|------|-------|\n",
    "| **K-BERT‑Retriever** | 2021 | Integrates BM25‑style retrieval with BERT. |\n",
    "| **K2N** | 2022 | Uses knowledge graphs for neural open‑domain QA. |\n",
    "| **KALM** | 2023 | Knowledge‑augmented Language Model with dynamic retrieval. |\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Text‑to‑KG Construction (Information Extraction)\n",
    "\n",
    "**Goal:** Populate or expand a KG from raw text.\n",
    "\n",
    "### Typical Steps\n",
    "1. **Named Entity Recognition (NER)** → Detect entities.\n",
    "2. **Relation Extraction** → Identify triples `(h, r, t)` via supervised or unsupervised methods.\n",
    "3. **Coreference & Entity Linking** → Resolve mentions to KG IDs.\n",
    "4. **KG Update** → Insert new triples, possibly with confidence scores.\n",
    "\n",
    "### State‑of‑the‑Art Systems\n",
    "- **Text2KG** (2019) – Jointly learns NER and relation extraction using a shared encoder.\n",
    "- **OpenIE‑KG** (2020) – Uses Open Information Extraction with a knowledge base mapping step.\n",
    "- **TACRED** + **HKG** – Benchmark datasets for training relation extraction models.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Cross‑Modal Retrieval / QA\n",
    "\n",
    "**Goal:** Bridge natural language queries and KG reasoning.\n",
    "\n",
    "### Common Architectures\n",
    "- **Dual‑Encoder**: One encoder for the query (BERT) and another for the KG (GCN). Use cosine similarity to retrieve top‑k triples.\n",
    "- **Joint‑Encoder**: Concatenate query and KG sub‑graph into one input sequence; fine‑tune on QA or classification.\n",
    "- **Reasoning Layer**: Apply multi‑hop reasoning on the KG (e.g., GNN or rule‑based) before matching with the query.\n",
    "\n",
    "### Notable Systems\n",
    "| System | Year | Use‑case |\n",
    "|--------|------|----------|\n",
    "| **K-BERT‑QA** | 2020 | Question answering with KG‑augmented BERT. |\n",
    "| **KIQA** | 2021 | Knowledge‑informed question answering benchmark. |\n",
    "| **TREC KBQA** | 2017 | Early benchmark for KG QA. |\n",
    "\n",
    "---\n",
    "\n",
    "## Practical Tips & Pitfalls\n",
    "\n",
    "| Tip | Why it matters |\n",
    "|-----|----------------|\n",
    "| **Entity Linking First** | Poor linking leads to noisy joint representations. |\n",
    "| **Scale the KG** | Large KGs can explode memory; use sampling or sub‑graph extraction. |\n",
    "| **Fine‑tune on Downstream Task** | Pre‑trained KG embeddings may need task‑specific adaptation. |\n",
    "| **Handle OOV Entities** | Use sub‑word embeddings or placeholder tokens. |\n",
    "| **Balance Text vs KG Loss** | Weighted loss terms prevent one modality from dominating. |\n",
    "| **Use Pre‑trained LMs** | Leverage BERT, RoBERTa, GPT‑2, etc., as strong backbones. |\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Starter Code Snippets\n",
    "\n",
    "### 1. Joint Encoder (PyTorch)\n",
    "\n",
    "```python\n",
    "import torch, torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class KGTextModel(nn.Module):\n",
    "    def __init__(self, kg_dim=256, txt_dim=768, num_rel=100):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.gcn1 = GCNConv(kg_dim, kg_dim)\n",
    "        self.gcn2 = GCNConv(kg_dim, kg_dim)\n",
    "        self.rel_emb = nn.Embedding(num_rel, kg_dim)\n",
    "        self.fc = nn.Linear(txt_dim + kg_dim, 2)  # e.g., classification\n",
    "\n",
    "    def forward(self, txt_input_ids, txt_attention_mask,\n",
    "                kg_x, kg_edge_index, kg_edge_type):\n",
    "        # Text encoder\n",
    "        txt_out = self.bert(txt_input_ids, attention_mask=txt_attention_mask)[0]\n",
    "        txt_rep = txt_out[:,0,:]  # CLS token\n",
    "\n",
    "        # KG encoder\n",
    "        kg_x = kg_x + self.rel_emb(kg_edge_type)\n",
    "        kg_x = torch.relu(self.gcn1(kg_x, kg_edge_index))\n",
    "        kg_x = torch.relu(self.gcn2(kg_x, kg_edge_index))\n",
    "        kg_rep = torch.mean(kg_x, dim=0)  # simple readout\n",
    "\n",
    "        # Fuse\n",
    "        fused = torch.cat([txt_rep, kg_rep], dim=-1)\n",
    "        logits = self.fc(fused)\n",
    "        return logits\n",
    "```\n",
    "\n",
    "### 2. Knowledge Retrieval with BM25 + BERT (Pseudo‑Code)\n",
    "\n",
    "```python\n",
    "# Preprocess KG triples into \"textual facts\"\n",
    "facts = [f\"{h} {r} {t}\" for h, r, t in triples]\n",
    "\n",
    "# Build BM25 index\n",
    "from rank_bm25 import BM25Okapi\n",
    "tokenized_facts = [fact.split() for fact in facts]\n",
    "bm25 = BM25Okapi(tokenized_facts)\n",
    "\n",
    "def retrieve(query, k=5):\n",
    "    tokenized_query = query.split()\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "    top_idx = scores.argsort()[-k:][::-1]\n",
    "    return [facts[i] for i in top_idx]\n",
    "\n",
    "# During inference\n",
    "retrieved = retrieve(user_query)\n",
    "# Encode retrieved facts with BERT + user query for final prediction\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Bibliography (Select)\n",
    "\n",
    "- **K-BERT** – X. Liu et al., 2020. *ACL*  \n",
    "- **KG-BERT** – C. Wang et al., 2019. *EMNLP*  \n",
    "- **ERNIE** – Y. Zhang et al., 2020. *ACL*  \n",
    "- **KEPLER** – Z. Wang et al., 2020. *ACL*  \n",
    "- **Text2KG** – Y. Ji et al., 2019. *ACL*  \n",
    "- **K-Adapter** – M. Li et al., 2021. *ACL*  \n",
    "- **K-GPT** – S. Liu et al., 2021. *NAACL*  \n",
    "- **KIQA** – S. B. Yang et al., 2021. *AAAI*  \n",
    "- **TACRED** – A. Liu et al., 2018. *ACL*  \n",
    "\n",
    "---\n",
    "\n",
    "### TL;DR\n",
    "\n",
    "1. **Learn embeddings that sit in the same space**: Use joint objectives (contrastive, multimodal) to align KG entities with text tokens.  \n",
    "2. **Let graphs talk to language models**: GCN/GraphSAGE + Transformers or specialized knowledge heads.  \n",
    "3. **Retrieve or condition on KG facts**: Dynamic retrieval or static “knowledge tokens” during inference.  \n",
    "4. **Build or extend KGs from text**: Joint NER/RE pipelines, then link to existing KG.  \n",
    "5. **Fine‑tune for your downstream task**: Even the best joint model still benefits from task‑specific fine‑tuning.\n",
    "\n",
    "With these strategies, you can harness the structured knowledge of KGs and the expressive power of modern language models to build smarter NLP systems. Happy hacking!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d842af0e-8ddc-43de-9a8a-94001f4e6bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context_for_rag(chunks):\n",
    "    context = \"\"\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        context += f\"Title: {chunk['title']}\\nAbstract: {chunk['summary']}\\n\\n\"\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e953b9f-e578-41c3-b70e-df25a9fbcd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "\n",
    "host='127.0.0.1:65383'\n",
    "model=\"gpt-oss:20b\"\n",
    "\n",
    "client = Client(\n",
    "    host=host,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ec2f93e4-6e4e-48d3-bb25-cd95e0190b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_ollama(context, question, client):\n",
    "    messages = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': f\"\"\"You are a helpful assistant. Answer the question below using the scientific literature provided.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for part in client.chat(model, messages=messages, stream=True):\n",
    "        print(part.message.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "60066358-a964-4698-86f5-36fdcd82755e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 53.60it/s]\n"
     ]
    }
   ],
   "source": [
    "chunks_kw = get_top_k_chunks(data2, query, mode=\"keywords\", top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2395e79e-6221-44e7-a6f2-e7d21e697c0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Approaches that explicitly fuse knowledge‑graph (KG) representations with natural‑language text**\n",
      "\n",
      "| Paper | Core idea of the KG–text fusion | Typical downstream tasks | Key observations |\n",
      "|-------|--------------------------------|---------------------------|------------------|\n",
      "| **LG4AV: Combining Language Models and Graph Neural Networks for Author Verification** | 1. Pass the *text* (title/abstract) through a pre‑trained transformer (e.g., BERT). <br>2. Project the transformer outputs into a graph‑aware embedding space using a Graph Neural Network (GNN) that operates on the co‑authorship graph. <br>3. Jointly train the transformer and GNN so that the textual representation is enriched with relational signals from the graph. | Authorship verification, especially for short scientific abstracts. | The GNN supplies *contextual* signals (e.g., co‑authorship, topical similarity) that compensate for the limited stylistic cues in short texts. |\n",
      "| **LinkNBed: Multi‑Graph Representation Learning with Entity Linkage** | 1. Learn embeddings jointly across *multiple* KGs (different corpora or domains). <br>2. Use an entity‑linkage module that aligns entities that appear in different graphs, thus allowing cross‑graph knowledge transfer. <br>3. Integrate side‑information such as textual descriptions or Wikipedia passages (if available) as additional modalities during joint training. | Link prediction, entity linkage, unified KG construction. | By aligning entities across graphs, LinkNBed can incorporate textual descriptions from one graph to disambiguate entities in another, achieving state‑of‑the‑art on link prediction benchmarks. |\n",
      "| **Learning Knowledge Graph‑based World Models of Textual Environments** | 1. Represent the *state* of a text‑based game as a KG (nodes = entities, edges = relations). <br>2. Use a transformer‑based encoder–decoder that takes both the KG and the *current textual observation* as input. <br>3. The model learns two tasks simultaneously: (i) predict the KG transition induced by an action; (ii) generate a set of *natural‑language actions* that are relevant in the current context. | World‑model learning for text‑based RL agents; zero‑shot transfer to unseen game worlds. | The fusion of KG dynamics and language generation gives the agent a *structured* understanding of the world that improves sample efficiency and generalization. |\n",
      "| **Fork or Fail: Cycle‑Consistent Training with Many‑to‑One Mappings** | 1. Treat *graph → text* and *text → graph* as two inverse problems. <br>2. Use a conditional VAE (CVAE) to model the *surjective* mapping from graphs to text, allowing multiple valid texts per graph. <br>3. Train a cycle‑consistency loss that reconstructs both the graph and the text while encouraging diversity in the one‑to‑many direction. | Graph‑to‑text generation (e.g., generating natural language from KG triples) and text‑to‑graph reconstruction. | The CVAE allows the model to learn the *distribution* of plausible textual realizations of a KG, mitigating the rigid bijection assumption that would otherwise hurt reconstruction quality. |\n",
      "| **HypE: Self‑Supervised Hyperboloid Representations from Logical Queries over Knowledge Graphs** | Although HypE is primarily a KG embedding method, it is *self‑supervised* on *logical queries* that can be formulated from textual descriptions of relations (e.g., “students of the same professor”). The learned hyperboloid embeddings can be mapped to textual semantic vectors via a learned linear transformation. | Query answering, anomaly detection in hierarchical taxonomies. | By representing KG entities in hyperbolic space, HypE captures hierarchical relationships that are also expressed in language, enabling richer cross‑modal inference. |\n",
      "\n",
      "### How these methods combine KG and text\n",
      "\n",
      "1. **Joint embedding spaces** – LG4AV and LinkNBed learn a common vector space where textual embeddings and graph embeddings coexist. This allows the model to borrow evidence from one modality to disambiguate or enrich the other.\n",
      "\n",
      "2. **Conditional generation** – Fork or Fail explicitly conditions the generation of text on a KG and vice versa, training a probabilistic mapping that can handle one‑to‑many relationships.\n",
      "\n",
      "3. **Structured world modeling** – The world‑model paper shows how a KG can be the backbone of a reinforcement‑learning environment, while the text interface (user prompts, descriptions) is the observable channel. The transformer acts as a bridge that translates between the two.\n",
      "\n",
      "4. **Self‑supervision via logical queries** – HypE exploits logical queries that often originate from textual descriptions (e.g., “who are the parents of X?”) to supervise KG embedding learning, making the embedding space useful for both symbolic reasoning and textual inference.\n",
      "\n",
      "### Take‑away\n",
      "\n",
      "- **Multi‑modal fusion** can be achieved either by *embedding alignment* (LG4AV, LinkNBed), *generative conditioning* (Fork or Fail), or *structured world modeling* (Learning KG‑based World Models).  \n",
      "- **Hyperbolic embeddings** (HypE) provide a way to encode hierarchical language semantics in the KG space, enabling transfer of reasoning capability between the two modalities.  \n",
      "- These approaches collectively demonstrate that knowledge graphs and text are complementary: the graph supplies relational structure, while text supplies rich contextual semantics. Their integration yields more robust, interpretable, and generalizable models for tasks ranging from authorship verification to AI‑driven text‑based games."
     ]
    }
   ],
   "source": [
    "answer_kw = query_ollama(build_context_for_rag(chunks_kw), query, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99641e60-9321-4ebc-a8dc-c4b616915e5d",
   "metadata": {},
   "source": [
    "**Approaches that explicitly fuse knowledge‑graph (KG) representations with natural‑language text**\n",
    "\n",
    "| Paper | Core idea of the KG–text fusion | Typical downstream tasks | Key observations |\n",
    "|-------|--------------------------------|---------------------------|------------------|\n",
    "| **LG4AV: Combining Language Models and Graph Neural Networks for Author Verification** | 1. Pass the *text* (title/abstract) through a pre‑trained transformer (e.g., BERT). <br>2. Project the transformer outputs into a graph‑aware embedding space using a Graph Neural Network (GNN) that operates on the co‑authorship graph. <br>3. Jointly train the transformer and GNN so that the textual representation is enriched with relational signals from the graph. | Authorship verification, especially for short scientific abstracts. | The GNN supplies *contextual* signals (e.g., co‑authorship, topical similarity) that compensate for the limited stylistic cues in short texts. |\n",
    "| **LinkNBed: Multi‑Graph Representation Learning with Entity Linkage** | 1. Learn embeddings jointly across *multiple* KGs (different corpora or domains). <br>2. Use an entity‑linkage module that aligns entities that appear in different graphs, thus allowing cross‑graph knowledge transfer. <br>3. Integrate side‑information such as textual descriptions or Wikipedia passages (if available) as additional modalities during joint training. | Link prediction, entity linkage, unified KG construction. | By aligning entities across graphs, LinkNBed can incorporate textual descriptions from one graph to disambiguate entities in another, achieving state‑of‑the‑art on link prediction benchmarks. |\n",
    "| **Learning Knowledge Graph‑based World Models of Textual Environments** | 1. Represent the *state* of a text‑based game as a KG (nodes = entities, edges = relations). <br>2. Use a transformer‑based encoder–decoder that takes both the KG and the *current textual observation* as input. <br>3. The model learns two tasks simultaneously: (i) predict the KG transition induced by an action; (ii) generate a set of *natural‑language actions* that are relevant in the current context. | World‑model learning for text‑based RL agents; zero‑shot transfer to unseen game worlds. | The fusion of KG dynamics and language generation gives the agent a *structured* understanding of the world that improves sample efficiency and generalization. |\n",
    "| **Fork or Fail: Cycle‑Consistent Training with Many‑to‑One Mappings** | 1. Treat *graph → text* and *text → graph* as two inverse problems. <br>2. Use a conditional VAE (CVAE) to model the *surjective* mapping from graphs to text, allowing multiple valid texts per graph. <br>3. Train a cycle‑consistency loss that reconstructs both the graph and the text while encouraging diversity in the one‑to‑many direction. | Graph‑to‑text generation (e.g., generating natural language from KG triples) and text‑to‑graph reconstruction. | The CVAE allows the model to learn the *distribution* of plausible textual realizations of a KG, mitigating the rigid bijection assumption that would otherwise hurt reconstruction quality. |\n",
    "| **HypE: Self‑Supervised Hyperboloid Representations from Logical Queries over Knowledge Graphs** | Although HypE is primarily a KG embedding method, it is *self‑supervised* on *logical queries* that can be formulated from textual descriptions of relations (e.g., “students of the same professor”). The learned hyperboloid embeddings can be mapped to textual semantic vectors via a learned linear transformation. | Query answering, anomaly detection in hierarchical taxonomies. | By representing KG entities in hyperbolic space, HypE captures hierarchical relationships that are also expressed in language, enabling richer cross‑modal inference. |\n",
    "\n",
    "### How these methods combine KG and text\n",
    "\n",
    "1. **Joint embedding spaces** – LG4AV and LinkNBed learn a common vector space where textual embeddings and graph embeddings coexist. This allows the model to borrow evidence from one modality to disambiguate or enrich the other.\n",
    "\n",
    "2. **Conditional generation** – Fork or Fail explicitly conditions the generation of text on a KG and vice versa, training a probabilistic mapping that can handle one‑to‑many relationships.\n",
    "\n",
    "3. **Structured world modeling** – The world‑model paper shows how a KG can be the backbone of a reinforcement‑learning environment, while the text interface (user prompts, descriptions) is the observable channel. The transformer acts as a bridge that translates between the two.\n",
    "\n",
    "4. **Self‑supervision via logical queries** – HypE exploits logical queries that often originate from textual descriptions (e.g., “who are the parents of X?”) to supervise KG embedding learning, making the embedding space useful for both symbolic reasoning and textual inference.\n",
    "\n",
    "### Take‑away\n",
    "\n",
    "- **Multi‑modal fusion** can be achieved either by *embedding alignment* (LG4AV, LinkNBed), *generative conditioning* (Fork or Fail), or *structured world modeling* (Learning KG‑based World Models).  \n",
    "- **Hyperbolic embeddings** (HypE) provide a way to encode hierarchical language semantics in the KG space, enabling transfer of reasoning capability between the two modalities.  \n",
    "- These approaches collectively demonstrate that knowledge graphs and text are complementary: the graph supplies relational structure, while text supplies rich contextual semantics. Their integration yields more robust, interpretable, and generalizable models for tasks ranging from authorship verification to AI‑driven text‑based games.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbda0b79-3c6d-4cf4-a6e4-b4393e791476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6a10040a-4980-4b60-a951-4cd0b9b381b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title: Attributes as Semantic Units between Natural Language and Visual Recognition\\nSummary: Impressive progress has been made in the fields of computer vision and\\nnatural language processing. However, it remains a challenge to find the best\\npoint of interaction for these very different modalities. In this chapter we\\ndiscuss how attributes allow us to exchange information between the two\\nmodalities and in this way lead to an interaction on a semantic level.\\nSpecifically we discuss how attributes allow using knowledge mined from\\nlanguage resources for recognizing novel visual categories, how we can generate\\nsentence description about images and video, how we can ground natural language\\nin visual content, and finally, how we can answer natural language questions\\nabout images.\\n\\nTitle: From Images to Sentences through Scene Description Graphs using Commonsense Reasoning and Knowledge\\nSummary: In this paper we propose the construction of linguistic descriptions of\\nimages. This is achieved through the extraction of scene description graphs\\n(SDGs) from visual scenes using an automatically constructed knowledge base.\\nSDGs are constructed using both vision and reasoning. Specifically, commonsense\\nreasoning is applied on (a) detections obtained from existing perception\\nmethods on given images, (b) a \"commonsense\" knowledge base constructed using\\nnatural language processing of image annotations and (c) lexical ontological\\nknowledge from resources such as WordNet. Amazon Mechanical Turk(AMT)-based\\nevaluations on Flickr8k, Flickr30k and MS-COCO datasets show that in most\\ncases, sentences auto-constructed from SDGs obtained by our method give a more\\nrelevant and thorough description of an image than a recent state-of-the-art\\nimage caption based approach. Our Image-Sentence Alignment Evaluation results\\nare also comparable to that of the recent state-of-the art approaches.\\n\\nTitle: Structured Neural Summarization\\nSummary: Summarization of long sequences into a concise statement is a core problem in\\nnatural language processing, requiring non-trivial understanding of the input.\\nBased on the promising results of graph neural networks on highly structured\\ndata, we develop a framework to extend existing sequence encoders with a graph\\ncomponent that can reason about long-distance relationships in weakly\\nstructured data such as text. In an extensive evaluation, we show that the\\nresulting hybrid sequence-graph models outperform both pure sequence models as\\nwell as pure graph models on a range of summarization tasks.\\n\\nTitle: TCNN: Triple Convolutional Neural Network Models for Retrieval-based Question Answering System in E-commerce\\nSummary: Automatic question-answering (QA) systems have boomed during last few years,\\nand commonly used techniques can be roughly categorized into Information\\nRetrieval (IR)-based and generation-based. A key solution to the IR based\\nmodels is to retrieve the most similar knowledge entries of a given query from\\na QA knowledge base, and then rerank those knowledge entries with semantic\\nmatching models. In this paper, we aim to improve an IR based e-commerce QA\\nsystem-AliMe with proposed text matching models, including a basic Triple\\nConvolutional Neural Network (TCNN) model and two Attention-based TCNN (ATCNN)\\nmodels. Experimental results show their effect.\\n\\nTitle: Structured Neural Summarization\\nSummary: Summarization of long sequences into a concise statement is a core problem in\\nnatural language processing, requiring non-trivial understanding of the input.\\nBased on the promising results of graph neural networks on highly structured\\ndata, we develop a framework to extend existing sequence encoders with a graph\\ncomponent that can reason about long-distance relationships in weakly\\nstructured data such as text. In an extensive evaluation, we show that the\\nresulting hybrid sequence-graph models outperform both pure sequence models as\\nwell as pure graph models on a range of summarization tasks.\\n\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_context_for_rag(chunks_sci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "48b9f1e6-6f87-41e0-b4b3-868d116f1cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Combining Knowledge Graphs (KGs) with Text: Representative Approaches**\n",
      "\n",
      "| # | Approach | Core Idea | How Text is Used | Key Results |\n",
      "|---|----------|-----------|------------------|-------------|\n",
      "| **1** | **Entity‑Context Graph (ECG)** | Extracts *entity‑centric* triples directly from semi‑structured web pages (e.g., Wikipedia infoboxes, product pages) and learns entity embeddings without building a full KG. | - Parses the text to identify “entity → value” pairs. <br> - Treats each pair as a lightweight triple (entity, *implicit* relation, value). <br> - Uses these triples to train a standard KG embedding model (e.g., TransE). | Embeddings obtained are **comparable to** traditional KG‑based embeddings, **better than** contextual LM‑based entity vectors, and **much cheaper** to generate. (R. Khan et al., *2023*) |\n",
      "| **2** | **Cross‑lingual KG Alignment via Graph‑Matching Neural Network** | Formulates alignment as a graph‑matching problem on *topic entity graphs*—local sub‑graphs that capture contextual information around each entity. | - For each entity, extracts a sub‑graph comprising neighboring entities and their relations (often derived from text‑extracted triples or descriptive sentences). <br> - Uses graph‑attention layers to compute an alignment score between two entities across languages. | Outperforms previous state‑of‑the‑art methods on several cross‑lingual benchmarks by leveraging *text‑derived context*. (Z. Liu et al., *2022*) |\n",
      "| **3** | **Type‑Augmented Relation Prediction (TaRP)** | Improves KG completion by incorporating *ontological type information* (entity & relation types) as a prior over the likelihood of a relation. | - Types are often extracted from the same textual sources that provide the instance‑level triples (e.g., infobox schemas, section headers). <br> - These types are encoded as prior probabilities and combined with likelihoods via Bayes’ rule. | Achieves significant gains on FB15K, YAGO, DBpedia benchmarks and demonstrates strong *data efficiency* and *cross‑dataset generalization*. (S. Zhang et al., *2023*) |\n",
      "\n",
      "---\n",
      "\n",
      "### How These Methods Blend Text and KG Knowledge\n",
      "\n",
      "1. **Text → Lightweight Triples → KG Embeddings**  \n",
      "   *ECG* bypasses full KG construction by turning natural‑language (semi‑structured) mentions into triples. The resulting “graph” is then fed into standard embedding algorithms.\n",
      "\n",
      "2. **Text → Contextual Sub‑Graphs → Graph Matching**  \n",
      "   *Cross‑lingual alignment* builds a *topic entity graph* from text‑derived relations. The graph‑attention network learns to align entities by comparing the *context* they appear in, which often comes from linguistic cues in the source text.\n",
      "\n",
      "3. **Text → Type Information → Probabilistic Prediction**  \n",
      "   *TaRP* uses types (e.g., “Person”, “Location”) that are normally inferred from the same documents that supply the raw triples. By treating type consistency as a prior, the model leverages textual ontology to guide missing‑relation inference.\n",
      "\n",
      "---\n",
      "\n",
      "### Take‑away\n",
      "\n",
      "All three approaches demonstrate that **text can be directly leveraged to enrich, build, or align KG representations**—without the heavy engineering cost of traditional triple extraction or large‑scale graph construction. They also illustrate a spectrum of strategies:\n",
      "\n",
      "- **Direct embedding from text** (ECG)  \n",
      "- **Contextual graph construction for cross‑lingual tasks** (Cross‑lingual Graph Matching)  \n",
      "- **Ontological priors derived from text** (TaRP)\n",
      "\n",
      "These paradigms can be mixed or extended—e.g., using language‑model embeddings as node features, or augmenting topic entity graphs with learned attention weights from transformer‑based encoders—providing a rich toolkit for anyone working at the intersection of KGs and natural language."
     ]
    }
   ],
   "source": [
    "chunks_mini = get_top_k_chunks(data2, query, mode=\"minilm\", top_k=5)\n",
    "answer_mini = query_ollama(build_context_for_rag(chunks_mini), query, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34def641-6af5-47fa-ad12-a0ceb5dee054",
   "metadata": {},
   "source": [
    "**Combining Knowledge Graphs (KGs) with Text: Representative Approaches**\n",
    "\n",
    "| # | Approach | Core Idea | How Text is Used | Key Results |\n",
    "|---|----------|-----------|------------------|-------------|\n",
    "| **1** | **Entity‑Context Graph (ECG)** | Extracts *entity‑centric* triples directly from semi‑structured web pages (e.g., Wikipedia infoboxes, product pages) and learns entity embeddings without building a full KG. | - Parses the text to identify “entity → value” pairs. <br> - Treats each pair as a lightweight triple (entity, *implicit* relation, value). <br> - Uses these triples to train a standard KG embedding model (e.g., TransE). | Embeddings obtained are **comparable to** traditional KG‑based embeddings, **better than** contextual LM‑based entity vectors, and **much cheaper** to generate. (R. Khan et al., *2023*) |\n",
    "| **2** | **Cross‑lingual KG Alignment via Graph‑Matching Neural Network** | Formulates alignment as a graph‑matching problem on *topic entity graphs*—local sub‑graphs that capture contextual information around each entity. | - For each entity, extracts a sub‑graph comprising neighboring entities and their relations (often derived from text‑extracted triples or descriptive sentences). <br> - Uses graph‑attention layers to compute an alignment score between two entities across languages. | Outperforms previous state‑of‑the‑art methods on several cross‑lingual benchmarks by leveraging *text‑derived context*. (Z. Liu et al., *2022*) |\n",
    "| **3** | **Type‑Augmented Relation Prediction (TaRP)** | Improves KG completion by incorporating *ontological type information* (entity & relation types) as a prior over the likelihood of a relation. | - Types are often extracted from the same textual sources that provide the instance‑level triples (e.g., infobox schemas, section headers). <br> - These types are encoded as prior probabilities and combined with likelihoods via Bayes’ rule. | Achieves significant gains on FB15K, YAGO, DBpedia benchmarks and demonstrates strong *data efficiency* and *cross‑dataset generalization*. (S. Zhang et al., *2023*) |\n",
    "\n",
    "---\n",
    "\n",
    "### How These Methods Blend Text and KG Knowledge\n",
    "\n",
    "1. **Text → Lightweight Triples → KG Embeddings**  \n",
    "   *ECG* bypasses full KG construction by turning natural‑language (semi‑structured) mentions into triples. The resulting “graph” is then fed into standard embedding algorithms.\n",
    "\n",
    "2. **Text → Contextual Sub‑Graphs → Graph Matching**  \n",
    "   *Cross‑lingual alignment* builds a *topic entity graph* from text‑derived relations. The graph‑attention network learns to align entities by comparing the *context* they appear in, which often comes from linguistic cues in the source text.\n",
    "\n",
    "3. **Text → Type Information → Probabilistic Prediction**  \n",
    "   *TaRP* uses types (e.g., “Person”, “Location”) that are normally inferred from the same documents that supply the raw triples. By treating type consistency as a prior, the model leverages textual ontology to guide missing‑relation inference.\n",
    "\n",
    "---\n",
    "\n",
    "### Take‑away\n",
    "\n",
    "All three approaches demonstrate that **text can be directly leveraged to enrich, build, or align KG representations**—without the heavy engineering cost of traditional triple extraction or large‑scale graph construction. They also illustrate a spectrum of strategies:\n",
    "\n",
    "- **Direct embedding from text** (ECG)  \n",
    "- **Contextual graph construction for cross‑lingual tasks** (Cross‑lingual Graph Matching)  \n",
    "- **Ontological priors derived from text** (TaRP)\n",
    "\n",
    "These paradigms can be mixed or extended—e.g., using language‑model embeddings as node features, or augmenting topic entity graphs with learned attention weights from transformer‑based encoders—providing a rich toolkit for anyone working at the intersection of KGs and natural language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "83921eb0-c5ef-4a20-90dc-9f77eb0f94b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 59.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Approaches that fuse knowledge‑graph (KG) structure with textual information**\n",
      "\n",
      "| # | Approach / Model | Core idea | How KG and text are combined | Typical use‑case |\n",
      "|---|------------------|-----------|------------------------------|-----------------|\n",
      "| 1 | **Attribute‑driven semantic units** (Attributes as Semantic Units chapter) | Visual concepts (attributes) are mined from language resources (e.g., WordNet, caption corpora) and used as semantic pivots between image features and natural language. | Attributes form a lightweight KG (attribute ↔ concept graph). Textual features (e.g., word embeddings) are aligned to the same attributes, enabling cross‑modal retrieval and captioning. | Image‑to‑text generation, visual grounding, VQA. |\n",
      "| 2 | **Scene Description Graphs (SDGs)** | Each image is parsed into a graph where nodes are objects, attributes, and relations; edges encode spatial/semantic relations. | The SDG is enriched by two external knowledge sources:<br>• A *commonsense* KB derived from image captions (NLP‑extracted predicates).<br>• WordNet lexical ontology (synset relations). The graph thus merges visual detections, commonsense inference, and lexical semantics. | Automatic image captioning, image‑sentence alignment, visual storytelling. |\n",
      "| 3 | **Graph‑enhanced neural summarization** (Structured Neural Summarization) | A conventional sequence encoder (e.g., Transformer) is augmented with a graph encoder that operates on a *dependency / discourse graph* extracted from the input text. | The graph captures long‑range dependencies that are hard to learn from the sequence alone. Textual tokens are first embedded, then passed through the graph neural network (GNN), and finally merged back into the sequence decoder. | Summarizing long documents, abstractive summarization. |\n",
      "| 4 | **Retrieval‑based QA with triple‑convolutional networks** (TCNN & ATCNN) | The system retrieves a set of candidate knowledge entries from a QA KB, then reranks them by semantic matching. | Knowledge entries are first embedded as *triples* (subject–predicate–object). TCNN convolutions capture local patterns over these triples, while attention layers align the query text to the triple embeddings. | E‑commerce QA, customer support chatbots. |\n",
      "| 5 | **Graph‑aware language models (not in the given titles but widely studied)** | Pre‑train language models on KG triples (e.g., ERNIE, K-BERT) or use KG embeddings as auxiliary signals. | KG embeddings are injected into the transformer layers or used to bias attention. | Question answering, entity linking, relation extraction. |\n",
      "| 6 | **Joint KG–text representation learning** | Learn a shared vector space for KG entities and textual contexts (e.g., via co‑training). | Text passages containing entity mentions are aligned with KG nodes; a shared encoder (e.g., BERT) is fine‑tuned on both types of data. | Entity disambiguation, KG completion. |\n",
      "\n",
      "---\n",
      "\n",
      "### Common patterns in these methods\n",
      "\n",
      "1. **Graph construction**  \n",
      "   * From visual detections (SDG) → node = object/attribute, edge = spatial/semantic relation.  \n",
      "   * From language corpora → nodes = entities/words, edges = dependency or co‑occurrence.  \n",
      "   * From structured KBs (e.g., Freebase) → raw RDF triples.\n",
      "\n",
      "2. **Feature fusion**  \n",
      "   * **Early fusion** – concatenate raw text embeddings with KG embeddings before the encoder.  \n",
      "   * **Late fusion** – process text and KG separately and combine scores (e.g., reranking).  \n",
      "   * **Mid‑level fusion** – use GNNs to refine textual representations guided by graph structure.\n",
      "\n",
      "3. **Inference or reasoning**  \n",
      "   * Use graph propagation (GNN, message passing) to capture multi‑hop relationships.  \n",
      "   * Apply rule‑based or probabilistic inference on the KG to enrich textual outputs (e.g., commonsense reasoning in SDG).\n",
      "\n",
      "4. **Evaluation**  \n",
      "   * End‑to‑end tasks: image captioning, VQA, summarization, QA.  \n",
      "   * Alignment metrics: BLEU, METEOR for captions; ROUGE for summaries; precision/recall for retrieval.\n",
      "\n",
      "---\n",
      "\n",
      "### Take‑away\n",
      "\n",
      "Approaches that merge knowledge graphs and text typically build a graph that captures semantic or relational structure (from vision, language, or curated KBs) and then apply neural or graph‑based methods to fuse this structured knowledge with unstructured textual signals. The fusion can be performed at multiple stages of the pipeline, enabling richer representations that improve performance on downstream tasks such as image captioning, question answering, and summarization."
     ]
    }
   ],
   "source": [
    "chunks_sci = get_top_k_chunks(data2, query, mode=\"scibert\", top_k=5)\n",
    "answer_sci = query_ollama(build_context_for_rag(chunks_sci), query, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef02f2c2-de36-42ac-9281-044ccb5d3b5e",
   "metadata": {},
   "source": [
    "**Approaches that fuse knowledge‑graph (KG) structure with textual information**\n",
    "\n",
    "| # | Approach / Model | Core idea | How KG and text are combined | Typical use‑case |\n",
    "|---|------------------|-----------|------------------------------|-----------------|\n",
    "| 1 | **Attribute‑driven semantic units** (Attributes as Semantic Units chapter) | Visual concepts (attributes) are mined from language resources (e.g., WordNet, caption corpora) and used as semantic pivots between image features and natural language. | Attributes form a lightweight KG (attribute ↔ concept graph). Textual features (e.g., word embeddings) are aligned to the same attributes, enabling cross‑modal retrieval and captioning. | Image‑to‑text generation, visual grounding, VQA. |\n",
    "| 2 | **Scene Description Graphs (SDGs)** | Each image is parsed into a graph where nodes are objects, attributes, and relations; edges encode spatial/semantic relations. | The SDG is enriched by two external knowledge sources:<br>• A *commonsense* KB derived from image captions (NLP‑extracted predicates).<br>• WordNet lexical ontology (synset relations). The graph thus merges visual detections, commonsense inference, and lexical semantics. | Automatic image captioning, image‑sentence alignment, visual storytelling. |\n",
    "| 3 | **Graph‑enhanced neural summarization** (Structured Neural Summarization) | A conventional sequence encoder (e.g., Transformer) is augmented with a graph encoder that operates on a *dependency / discourse graph* extracted from the input text. | The graph captures long‑range dependencies that are hard to learn from the sequence alone. Textual tokens are first embedded, then passed through the graph neural network (GNN), and finally merged back into the sequence decoder. | Summarizing long documents, abstractive summarization. |\n",
    "| 4 | **Retrieval‑based QA with triple‑convolutional networks** (TCNN & ATCNN) | The system retrieves a set of candidate knowledge entries from a QA KB, then reranks them by semantic matching. | Knowledge entries are first embedded as *triples* (subject–predicate–object). TCNN convolutions capture local patterns over these triples, while attention layers align the query text to the triple embeddings. | E‑commerce QA, customer support chatbots. |\n",
    "| 5 | **Graph‑aware language models (not in the given titles but widely studied)** | Pre‑train language models on KG triples (e.g., ERNIE, K-BERT) or use KG embeddings as auxiliary signals. | KG embeddings are injected into the transformer layers or used to bias attention. | Question answering, entity linking, relation extraction. |\n",
    "| 6 | **Joint KG–text representation learning** | Learn a shared vector space for KG entities and textual contexts (e.g., via co‑training). | Text passages containing entity mentions are aligned with KG nodes; a shared encoder (e.g., BERT) is fine‑tuned on both types of data. | Entity disambiguation, KG completion. |\n",
    "\n",
    "---\n",
    "\n",
    "### Common patterns in these methods\n",
    "\n",
    "1. **Graph construction**  \n",
    "   * From visual detections (SDG) → node = object/attribute, edge = spatial/semantic relation.  \n",
    "   * From language corpora → nodes = entities/words, edges = dependency or co‑occurrence.  \n",
    "   * From structured KBs (e.g., Freebase) → raw RDF triples.\n",
    "\n",
    "2. **Feature fusion**  \n",
    "   * **Early fusion** – concatenate raw text embeddings with KG embeddings before the encoder.  \n",
    "   * **Late fusion** – process text and KG separately and combine scores (e.g., reranking).  \n",
    "   * **Mid‑level fusion** – use GNNs to refine textual representations guided by graph structure.\n",
    "\n",
    "3. **Inference or reasoning**  \n",
    "   * Use graph propagation (GNN, message passing) to capture multi‑hop relationships.  \n",
    "   * Apply rule‑based or probabilistic inference on the KG to enrich textual outputs (e.g., commonsense reasoning in SDG).\n",
    "\n",
    "4. **Evaluation**  \n",
    "   * End‑to‑end tasks: image captioning, VQA, summarization, QA.  \n",
    "   * Alignment metrics: BLEU, METEOR for captions; ROUGE for summaries; precision/recall for retrieval.\n",
    "\n",
    "---\n",
    "\n",
    "### Take‑away\n",
    "\n",
    "Approaches that merge knowledge graphs and text typically build a graph that captures semantic or relational structure (from vision, language, or curated KBs) and then apply neural or graph‑based methods to fuse this structured knowledge with unstructured textual signals. The fusion can be performed at multiple stages of the pipeline, enabling richer representations that improve performance on downstream tasks such as image captioning, question answering, and summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ea8ff1-73fa-4c3f-b2b9-5509b66de496",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d2693998-9315-4e8b-9f3c-b24bcdd1c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_eval_prompt(query, context, answer):\n",
    "    return f\"\"\"\n",
    "You are an expert evaluator judging a RAG (retrieval-augmented generation) system for scientific literature review.\n",
    "\n",
    "## Query:\n",
    "{query}\n",
    "\n",
    "## Retrieved Context:\n",
    "{context}\n",
    "\n",
    "## Generated Answer:\n",
    "{answer}\n",
    "\n",
    "Evaluate the following:\n",
    "\n",
    "1. **Context Relevance (1–5):** How well does the context match the query?\n",
    "2. **Answer Relevance (1–5):** How directly does the answer address the query?\n",
    "3. **Groundedness (1–5):** How well is the answer supported by the context?\n",
    "\n",
    "Provide a short explanation for each score.\n",
    "\n",
    "Respond strictly in the following JSON format:\n",
    "\n",
    "{{\n",
    "  \"context_relevance\": X,\n",
    "  \"answer_relevance\": Y,\n",
    "  \"groundedness\": Z,\n",
    "  \"justification\": {{\n",
    "    \"context\": \"...\",\n",
    "    \"answer\": \"...\",\n",
    "    \"grounding\": \"...\"\n",
    "  }}\n",
    "}}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da826a42-020c-4287-b934-329b06ef21b7",
   "metadata": {},
   "source": [
    "## Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dfa793cb-45ac-48e6-8783-8ca03212695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Approaches combining knowledge graphs and text\"\n",
    "context = build_context_for_rag(chunks_kw)\n",
    "answer = \"\"\"**Approaches that explicitly fuse knowledge‑graph (KG) representations with natural‑language text**\n",
    "\n",
    "| Paper | Core idea of the KG–text fusion | Typical downstream tasks | Key observations |\n",
    "|-------|--------------------------------|---------------------------|------------------|\n",
    "| **LG4AV: Combining Language Models and Graph Neural Networks for Author Verification** | 1. Pass the *text* (title/abstract) through a pre‑trained transformer (e.g., BERT). <br>2. Project the transformer outputs into a graph‑aware embedding space using a Graph Neural Network (GNN) that operates on the co‑authorship graph. <br>3. Jointly train the transformer and GNN so that the textual representation is enriched with relational signals from the graph. | Authorship verification, especially for short scientific abstracts. | The GNN supplies *contextual* signals (e.g., co‑authorship, topical similarity) that compensate for the limited stylistic cues in short texts. |\n",
    "| **LinkNBed: Multi‑Graph Representation Learning with Entity Linkage** | 1. Learn embeddings jointly across *multiple* KGs (different corpora or domains). <br>2. Use an entity‑linkage module that aligns entities that appear in different graphs, thus allowing cross‑graph knowledge transfer. <br>3. Integrate side‑information such as textual descriptions or Wikipedia passages (if available) as additional modalities during joint training. | Link prediction, entity linkage, unified KG construction. | By aligning entities across graphs, LinkNBed can incorporate textual descriptions from one graph to disambiguate entities in another, achieving state‑of‑the‑art on link prediction benchmarks. |\n",
    "| **Learning Knowledge Graph‑based World Models of Textual Environments** | 1. Represent the *state* of a text‑based game as a KG (nodes = entities, edges = relations). <br>2. Use a transformer‑based encoder–decoder that takes both the KG and the *current textual observation* as input. <br>3. The model learns two tasks simultaneously: (i) predict the KG transition induced by an action; (ii) generate a set of *natural‑language actions* that are relevant in the current context. | World‑model learning for text‑based RL agents; zero‑shot transfer to unseen game worlds. | The fusion of KG dynamics and language generation gives the agent a *structured* understanding of the world that improves sample efficiency and generalization. |\n",
    "| **Fork or Fail: Cycle‑Consistent Training with Many‑to‑One Mappings** | 1. Treat *graph → text* and *text → graph* as two inverse problems. <br>2. Use a conditional VAE (CVAE) to model the *surjective* mapping from graphs to text, allowing multiple valid texts per graph. <br>3. Train a cycle‑consistency loss that reconstructs both the graph and the text while encouraging diversity in the one‑to‑many direction. | Graph‑to‑text generation (e.g., generating natural language from KG triples) and text‑to‑graph reconstruction. | The CVAE allows the model to learn the *distribution* of plausible textual realizations of a KG, mitigating the rigid bijection assumption that would otherwise hurt reconstruction quality. |\n",
    "| **HypE: Self‑Supervised Hyperboloid Representations from Logical Queries over Knowledge Graphs** | Although HypE is primarily a KG embedding method, it is *self‑supervised* on *logical queries* that can be formulated from textual descriptions of relations (e.g., “students of the same professor”). The learned hyperboloid embeddings can be mapped to textual semantic vectors via a learned linear transformation. | Query answering, anomaly detection in hierarchical taxonomies. | By representing KG entities in hyperbolic space, HypE captures hierarchical relationships that are also expressed in language, enabling richer cross‑modal inference. |\n",
    "\n",
    "### How these methods combine KG and text\n",
    "\n",
    "1. **Joint embedding spaces** – LG4AV and LinkNBed learn a common vector space where textual embeddings and graph embeddings coexist. This allows the model to borrow evidence from one modality to disambiguate or enrich the other.\n",
    "\n",
    "2. **Conditional generation** – Fork or Fail explicitly conditions the generation of text on a KG and vice versa, training a probabilistic mapping that can handle one‑to‑many relationships.\n",
    "\n",
    "3. **Structured world modeling** – The world‑model paper shows how a KG can be the backbone of a reinforcement‑learning environment, while the text interface (user prompts, descriptions) is the observable channel. The transformer acts as a bridge that translates between the two.\n",
    "\n",
    "4. **Self‑supervision via logical queries** – HypE exploits logical queries that often originate from textual descriptions (e.g., “who are the parents of X?”) to supervise KG embedding learning, making the embedding space useful for both symbolic reasoning and textual inference.\n",
    "\n",
    "### Take‑away\n",
    "\n",
    "- **Multi‑modal fusion** can be achieved either by *embedding alignment* (LG4AV, LinkNBed), *generative conditioning* (Fork or Fail), or *structured world modeling* (Learning KG‑based World Models).  \n",
    "- **Hyperbolic embeddings** (HypE) provide a way to encode hierarchical language semantics in the KG space, enabling transfer of reasoning capability between the two modalities.  \n",
    "- These approaches collectively demonstrate that knowledge graphs and text are complementary: the graph supplies relational structure, while text supplies rich contextual semantics. Their integration yields more robust, interpretable, and generalizable models for tasks ranging from authorship verification to AI‑driven text‑based games.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e3b2e6d4-5181-423a-9f87-4f88e5042532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"context_relevance\": 5,\n",
      "  \"answer_relevance\": 5,\n",
      "  \"groundedness\": 3,\n",
      "  \"justification\": {\n",
      "    \"context\": \"The retrieved context lists several papers that are explicitly about combining knowledge graphs and text, such as LG4AV, LinkNBed, the world‑model paper, and others. This matches the query well, so the context relevance is high.\",\n",
      "    \"answer\": \"The answer directly lists and summarizes these papers, describing how they fuse KG and text representations. It addresses the query by providing concrete approaches, so answer relevance is high.\",\n",
      "    \"grounding\": \"While the answer cites the correct papers, some specific claims (e.g., use of Wikipedia passages in LinkNBed, mapping HypE embeddings to textual semantic vectors) are not directly supported by the provided context summaries. Thus the grounding is only partial, warranting a moderate score.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = format_eval_prompt(query, context, answer)\n",
    "\n",
    "messages = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': format_eval_prompt(query, context, answer),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "raw =  client.chat(model, messages=messages, stream=False)\n",
    "print(raw.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7196965-6693-4498-9a61-5af53fa2a11c",
   "metadata": {},
   "source": [
    "## Mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7bbb754b-b538-4b3c-bbb0-98e511e15117",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Approaches combining knowledge graphs and text\"\n",
    "context = build_context_for_rag(chunks_mini)\n",
    "answer = \"\"\"**Combining Knowledge Graphs (KGs) with Text: Representative Approaches**\n",
    "\n",
    "| # | Approach | Core Idea | How Text is Used | Key Results |\n",
    "|---|----------|-----------|------------------|-------------|\n",
    "| **1** | **Entity‑Context Graph (ECG)** | Extracts *entity‑centric* triples directly from semi‑structured web pages (e.g., Wikipedia infoboxes, product pages) and learns entity embeddings without building a full KG. | - Parses the text to identify “entity → value” pairs. <br> - Treats each pair as a lightweight triple (entity, *implicit* relation, value). <br> - Uses these triples to train a standard KG embedding model (e.g., TransE). | Embeddings obtained are **comparable to** traditional KG‑based embeddings, **better than** contextual LM‑based entity vectors, and **much cheaper** to generate. (R. Khan et al., *2023*) |\n",
    "| **2** | **Cross‑lingual KG Alignment via Graph‑Matching Neural Network** | Formulates alignment as a graph‑matching problem on *topic entity graphs*—local sub‑graphs that capture contextual information around each entity. | - For each entity, extracts a sub‑graph comprising neighboring entities and their relations (often derived from text‑extracted triples or descriptive sentences). <br> - Uses graph‑attention layers to compute an alignment score between two entities across languages. | Outperforms previous state‑of‑the‑art methods on several cross‑lingual benchmarks by leveraging *text‑derived context*. (Z. Liu et al., *2022*) |\n",
    "| **3** | **Type‑Augmented Relation Prediction (TaRP)** | Improves KG completion by incorporating *ontological type information* (entity & relation types) as a prior over the likelihood of a relation. | - Types are often extracted from the same textual sources that provide the instance‑level triples (e.g., infobox schemas, section headers). <br> - These types are encoded as prior probabilities and combined with likelihoods via Bayes’ rule. | Achieves significant gains on FB15K, YAGO, DBpedia benchmarks and demonstrates strong *data efficiency* and *cross‑dataset generalization*. (S. Zhang et al., *2023*) |\n",
    "\n",
    "---\n",
    "\n",
    "### How These Methods Blend Text and KG Knowledge\n",
    "\n",
    "1. **Text → Lightweight Triples → KG Embeddings**  \n",
    "   *ECG* bypasses full KG construction by turning natural‑language (semi‑structured) mentions into triples. The resulting “graph” is then fed into standard embedding algorithms.\n",
    "\n",
    "2. **Text → Contextual Sub‑Graphs → Graph Matching**  \n",
    "   *Cross‑lingual alignment* builds a *topic entity graph* from text‑derived relations. The graph‑attention network learns to align entities by comparing the *context* they appear in, which often comes from linguistic cues in the source text.\n",
    "\n",
    "3. **Text → Type Information → Probabilistic Prediction**  \n",
    "   *TaRP* uses types (e.g., “Person”, “Location”) that are normally inferred from the same documents that supply the raw triples. By treating type consistency as a prior, the model leverages textual ontology to guide missing‑relation inference.\n",
    "\n",
    "---\n",
    "\n",
    "### Take‑away\n",
    "\n",
    "All three approaches demonstrate that **text can be directly leveraged to enrich, build, or align KG representations**—without the heavy engineering cost of traditional triple extraction or large‑scale graph construction. They also illustrate a spectrum of strategies:\n",
    "\n",
    "- **Direct embedding from text** (ECG)  \n",
    "- **Contextual graph construction for cross‑lingual tasks** (Cross‑lingual Graph Matching)  \n",
    "- **Ontological priors derived from text** (TaRP)\n",
    "\n",
    "These paradigms can be mixed or extended—e.g., using language‑model embeddings as node features, or augmenting topic entity graphs with learned attention weights from transformer‑based encoders—providing a rich toolkit for anyone working at the intersection of KGs and natural language.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d7205838-6b0c-4f3e-817a-40b437d56e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"context_relevance\": 5,\n",
      "  \"answer_relevance\": 5,\n",
      "  \"groundedness\": 5,\n",
      "  \"justification\": {\n",
      "    \"context\": \"The retrieved snippets directly cover the three papers that discuss how text can be used to build, align, or enrich knowledge graphs, so the context is highly relevant to the query about KG–text approaches.\",\n",
      "    \"answer\": \"The answer enumerates exactly those three approaches, describing how text is leveraged in each, and highlights their results, which directly responds to the query.\",\n",
      "    \"grounding\": \"Each item in the answer maps to one of the provided article summaries: Entity‑Context Graph from the first snippet, Cross‑lingual KG Alignment from the third, and Type‑Augmented Relation Prediction from the fourth. The claims about embeddings, graph‑matching, and type priors are all supported by the corresponding context descriptions.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = format_eval_prompt(query, context, answer)\n",
    "\n",
    "messages = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': format_eval_prompt(query, context, answer),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "raw =  client.chat(model, messages=messages, stream=False)\n",
    "print(raw.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07afb345-3dd6-4a26-8f74-7b407b0d2cb3",
   "metadata": {},
   "source": [
    "## Sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6421bf0f-5571-4462-a159-170bc90bdd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Approaches combining knowledge graphs and text\"\n",
    "context = build_context_for_rag(chunks_sci)\n",
    "answer = \"\"\"**Approaches that fuse knowledge‑graph (KG) structure with textual information**\n",
    "\n",
    "| # | Approach / Model | Core idea | How KG and text are combined | Typical use‑case |\n",
    "|---|------------------|-----------|------------------------------|-----------------|\n",
    "| 1 | **Attribute‑driven semantic units** (Attributes as Semantic Units chapter) | Visual concepts (attributes) are mined from language resources (e.g., WordNet, caption corpora) and used as semantic pivots between image features and natural language. | Attributes form a lightweight KG (attribute ↔ concept graph). Textual features (e.g., word embeddings) are aligned to the same attributes, enabling cross‑modal retrieval and captioning. | Image‑to‑text generation, visual grounding, VQA. |\n",
    "| 2 | **Scene Description Graphs (SDGs)** | Each image is parsed into a graph where nodes are objects, attributes, and relations; edges encode spatial/semantic relations. | The SDG is enriched by two external knowledge sources:<br>• A *commonsense* KB derived from image captions (NLP‑extracted predicates).<br>• WordNet lexical ontology (synset relations). The graph thus merges visual detections, commonsense inference, and lexical semantics. | Automatic image captioning, image‑sentence alignment, visual storytelling. |\n",
    "| 3 | **Graph‑enhanced neural summarization** (Structured Neural Summarization) | A conventional sequence encoder (e.g., Transformer) is augmented with a graph encoder that operates on a *dependency / discourse graph* extracted from the input text. | The graph captures long‑range dependencies that are hard to learn from the sequence alone. Textual tokens are first embedded, then passed through the graph neural network (GNN), and finally merged back into the sequence decoder. | Summarizing long documents, abstractive summarization. |\n",
    "| 4 | **Retrieval‑based QA with triple‑convolutional networks** (TCNN & ATCNN) | The system retrieves a set of candidate knowledge entries from a QA KB, then reranks them by semantic matching. | Knowledge entries are first embedded as *triples* (subject–predicate–object). TCNN convolutions capture local patterns over these triples, while attention layers align the query text to the triple embeddings. | E‑commerce QA, customer support chatbots. |\n",
    "| 5 | **Graph‑aware language models (not in the given titles but widely studied)** | Pre‑train language models on KG triples (e.g., ERNIE, K-BERT) or use KG embeddings as auxiliary signals. | KG embeddings are injected into the transformer layers or used to bias attention. | Question answering, entity linking, relation extraction. |\n",
    "| 6 | **Joint KG–text representation learning** | Learn a shared vector space for KG entities and textual contexts (e.g., via co‑training). | Text passages containing entity mentions are aligned with KG nodes; a shared encoder (e.g., BERT) is fine‑tuned on both types of data. | Entity disambiguation, KG completion. |\n",
    "\n",
    "---\n",
    "\n",
    "### Common patterns in these methods\n",
    "\n",
    "1. **Graph construction**  \n",
    "   * From visual detections (SDG) → node = object/attribute, edge = spatial/semantic relation.  \n",
    "   * From language corpora → nodes = entities/words, edges = dependency or co‑occurrence.  \n",
    "   * From structured KBs (e.g., Freebase) → raw RDF triples.\n",
    "\n",
    "2. **Feature fusion**  \n",
    "   * **Early fusion** – concatenate raw text embeddings with KG embeddings before the encoder.  \n",
    "   * **Late fusion** – process text and KG separately and combine scores (e.g., reranking).  \n",
    "   * **Mid‑level fusion** – use GNNs to refine textual representations guided by graph structure.\n",
    "\n",
    "3. **Inference or reasoning**  \n",
    "   * Use graph propagation (GNN, message passing) to capture multi‑hop relationships.  \n",
    "   * Apply rule‑based or probabilistic inference on the KG to enrich textual outputs (e.g., commonsense reasoning in SDG).\n",
    "\n",
    "4. **Evaluation**  \n",
    "   * End‑to‑end tasks: image captioning, VQA, summarization, QA.  \n",
    "   * Alignment metrics: BLEU, METEOR for captions; ROUGE for summaries; precision/recall for retrieval.\n",
    "\n",
    "---\n",
    "\n",
    "### Take‑away\n",
    "\n",
    "Approaches that merge knowledge graphs and text typically build a graph that captures semantic or relational structure (from vision, language, or curated KBs) and then apply neural or graph‑based methods to fuse this structured knowledge with unstructured textual signals. The fusion can be performed at multiple stages of the pipeline, enabling richer representations that improve performance on downstream tasks such as image captioning, question answering, and summarization.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "86cf52ae-ab46-4111-b859-1eb0605a3d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"context_relevance\": 5,\n",
      "  \"answer_relevance\": 5,\n",
      "  \"groundedness\": 4,\n",
      "  \"justification\": {\n",
      "    \"context\": \"The answer discusses exactly the papers and concepts present in the retrieved context (attributes, SDGs, structured summarization, TCNN). It aligns the answer’s content with the titles and summaries provided.\",\n",
      "    \"answer\": \"The answer directly addresses the query by summarizing various approaches that combine knowledge graphs with text, matching the intent of the question.\",\n",
      "    \"grounding\": \"The answer cites the core ideas from each paper in the context, but also adds additional related methods (e.g., graph‑aware language models, joint KG–text representation learning) that were not explicitly present in the retrieved snippets.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = format_eval_prompt(query, context, answer)\n",
    "\n",
    "messages = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': format_eval_prompt(query, context, answer),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "raw =  client.chat(model, messages=messages, stream=False)\n",
    "print(raw.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9c427fd4-2b45-4044-b3a6-7998362f13cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = json.loads(raw.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f6918a-c050-413f-80ff-ab8388f4ce88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb0b9a2-b815-42b5-9aeb-549c2c9e2e10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Winter School - RAG",
   "language": "python",
   "name": "rag2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
